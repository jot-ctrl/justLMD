activation: gelu
archiname: transformer
batch_size: 20
cuda: true
dataset: lm2d
debug: false
expname: exps
folder: exps/lm2d
glob: true
glob_rot:
- 3.141592653589793
- 0
- 0
jointstype: vertices
lambda_kl: 1.0e-05
lambda_rc: 1.0
lambda_rcxyz: 1.0
lambdas:
  kl: 1.0e-05
  rc: 1.0
latent_dim: 256
losses:
- rc
- kl
lr: 0.0001
max_len: -1
min_len: -1
modelname: cvae_transformer_rc_rcxyz_kl
modeltype: cvae
nfeats: 3
njoints: 24
no-vertstrans: false
num_classes: 896
num_epochs: 5000
num_frames: 180
num_layers: 4
num_seq_max: -1
pose_rep: rot6d
sampling: conseq
sampling_step: 1
snapshot: 100
translation: true
vertstrans: false
